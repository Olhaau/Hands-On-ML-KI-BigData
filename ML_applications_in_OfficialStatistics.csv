Institution;Project name;Application;Comment;Status;Method;Software;Description of the project
 Federal Statistical Office of Germany     ; Assignment of enterprises in the business register to the institutional sectors8 ;Classification;"assignment of enterprises to the institutional sectors; uses SVM"; Productive      ; SVM      ; R      ; Support vector machines are used for the assignment of enterprises to the institutional sectors according to the European System of National Accounts (ESA) 2010. In this way, official statistics in Germany are entering new territory and creating an opportunity to replace costly searches carried out by humans to classify many individual cases in the future through this method of machine learning.
 Federal Statistical Office of Germany            ; Recognition of irrelevant enterprises in the craft statistics9         ;Classification;"recognition of irrelevant enterprises in the craft statistics instead of manual classification; uses SVM, RF and dimension reduction"; Productive             ; SVM, Random Forest            ; R             ; The craft statistics are currently determined completely from administrative data. However, not all enterprises included in deliveries from chambers of crafts are relevant for craft statistics. Irrelevant enterprises have to be identified by the statistical offices of the Länder. Since the work on manual classification ties up personnel resources to a considerable extent, the question arose as to whether enterprises can be classified automatically with sufficient accuracy. Support Vector Machines in conjunction with Random Forests are currently used to classify enterprises as relevant or irrelevant with relatively little personnel effort. The training and test data originates from the statistical business register. After a few steps to reduce the dimensions, a Support Vector Machine is adapted to a data set of approximately 80,000 units with 30 characteristics.
 Federal Statistical Office of Germany               ; Estimation of the interruption of employment due to motherhood10           ;Classification;For a adjustment of the gender pay gap, the employment interruption due to birth should be taken into account. The microcensus provided train/test data to classify female employees as non-/mothers.; Research paper                ; SVM, Random Forest, logistic regression              ; R                ;"In order to approach the missing characteristic ""true work experience of a female employee"" for the estimation of the adjusted gender pay gap, the data of the Structure of Earnings Survey (SES) should be enriched by a woman-specific variable ""employment interruption due to the birth of a child (yes/no)"". This would enable the Federal Statistical Office to take this form of career interruption into account when estimating the adjusted gender pay gap. The 2012 microcensus contains the (albeit voluntary) characteristic ""Did you give birth to children?"", which was interpreted as an indication of the existence of a career interruption. The microcensus as external source therefore provided the training and test data to classify female employees as mothers and non-mothers. The experimental estimation of maternity among female employees included in the SES sample for 2014 yielded results that were included in the model for calculating the adjusted gender pay gap, but only reduced it in the range of the statistical uncertainty that existed anyway."
 Federal Statistical Office of Germany             ; Estimation of citizenship (German/forei gner) of employees in the Structure of Earnings Survey11       ;Classification; Binary classification              ; Experiment              ; SVM (among others)              ; R              ;" Another characteristic not currently covered by the Structure of Earnings Survey (SES) is the nationality of employees. Again, the microcensus as external source provided the training and test data to classify employees as Germans and foreigners. The following difficulty arose: The group of respondents in the microcensus with purely non-German citizenship is so small that each classification procedure ""sacrifices"" this group to achieve a low rate of misclassification; in other words, all foreigners are classified as Germans. Different approaches to dealing with so-called unbalanced data were therefore examined with limited access. However, the results were not convincing: Obviously, foreigners and Germans are too ""similar"" in the microcensus to be classified sufficiently well with the classical methods and machine-learning procedures used so far on the basis of the common characteristics of SES and microcensus. Studies based on other data sources have not yet been carried out."
Federal Statistical Office of Germany;"Transfer of the ""minimum wage"" property to the Integrated Employment Biographies (IEB) data12";Classification;"IEB (panel) is missing ""affectedness to min. wage"", which is includes in the SES. Idea is to train a RF w/ SES and apply the model to IEB.";Ongoing test;Random Forest;R;The cross sectional Structure of Earnings Survey (SES) has information on the hourly wages and therefore also on whether employees are affected by the German minimum wage. This data is missing in the Integrated Employment Biographies (IEB), a panel provided by the Federal Employment Agency (BA/IAB). The idea is to enrich the panel data with the information on the minimum wage affection by training a random forest with the SES data and then applying it to the panel data.
Federal Statistical Office of Germany;classification of online job advertisement s;Classification;Text classification;Test;kNN, Multinomial- Naive-Bayes;Python (NLTK, SKlearn), R;Scraped online job advertisements are usually available in unstructured full text. There is often a lack of separate information, such as the economic sector, the desired level of education or whether the advertisement was placed by a recruiter or not. An ML approach should automatically carry out such classifications.
Federal Statistical Office of Germany;Use of scanner data in consumer price statistics;Classification;For the use of scanner data,  via their product description articles are assigned  to their ECOICOP classification.;Test;SVM,Random Forest,Logistic Regression;The tool is programmed in Java and Ember.js as a web service.;Assignment of articles via their product descriptions to the ECOICOP classification. Eurostat has had a tool programmed which is to be adapted to the German situation.
Federal Statistical Office of Germany;Check the coding of part- time employment as part of the SV key of the BA (Federal Employment Agency) in the Structure of Earnings Survey (VSE).;Classification;Binary classification;Test;Random Forest;R (Ranger);The SV key of the BA, in which part-time employment is also coded, is also collected in the VSE. Erroneous information is corrected within the framework of plausibility checks on the basis of information on working time. Objective: With the corrected values, a model for predicting part-time work is learned and then applied to the erroneous BA data. The misclassifications then provide indications of cases in which part-time employment is incorrectly coded in the BA data.
RKI / ZBS 6;Identification, differentiation and classification of biological samples such as cells, tissues and microorganis ms based on spectroscopic and spectrometric data;Classification;Differentiation, identification, classification;Research projects;ANN SVM Strategies for Optimization;NeuroDeveloper Matlab Matlab NN Toolbox Biotools ga_orstooldiag SNNS;"The ZBS 6 department of the RKI has been using methods of machine learning and artificial intelligence (AI) for more than 20 years. Among other things, variants of artificial neural networks (ANNs) are used, which enable pattern recognition based on spectral data, e.g. from vibration spectroscopy or mass spectrometry. Spectroscopic and spectrometric data are recorded from complex biological samples such as cells, tissues, etc.; the aim of the application of ANNs is the fast, objective and cost-effective identification, differentiation and classification in cytology, histology and microbiology within the framework of research activities or for method development in diagnostics."
RKI / MF1;Bioinformatics / Analysis of molecular data14;Classification;" Binary classification  (binary and
multiclass
problems),
regression,
clustering";Research projects and productive operation;Random Forests, Deep Learning;R, Python;Various methods of machine learning are developed and used for the analysis of large data sets from omics experiments such as genome sequencing, automated assistance systems. These data sets are so large (sometimes up to one billion genome fragments from a single experiment) that manual analysis is not fully useful or possible, especially for time-critical processes. This can be used, for example, to characterise bacterial or viral pathogens or to search for pathogens. The assistance systems are used in particular to identify irrelevant measurements for the human decision-maker, e.g. genome fragments that were only measured with low quality, that have biologically low information content or contain contaminations from measurement, environment or a host organism. In addition, special hazard potentials of individual measurements (e.g. proximity to known pathogens or relevant potential phenotypes such as virulence or resistance) for the human decision-maker are highlighted.
Centre for European Economic Research (ZEW);TOBI - Text Data-Based Output Indicators as the basis for a new innovation metric 17;Classification;Text analysis and classification;Under development;Miscellaneous;Python;New output indicators for innovation activities are being developed in the joint project. Computational linguistic methods are used, which are applied to large amounts of text data. The development of the methods and validation of the generated indicators is carried out by the ZEW in Mannheim and the Justus-Liebig-University GieÃƒÅ¸en. At the ZEW, the analysis is based on text content from company websites, which is collected automatically and regularly via a web scraper. Using text data mining (e.g. topic models), information on innovations is then identified from these texts and innovation indicators are derived. The websites are accessed on the basis of the databases available at the ZEW. These allow the continuous monitoring of the websites of the current German company stock and the consideration of extensive metadata (e.g. industry and location of the company). In addition, the newly generated innovation indicators can be compared with conventional innovation indicators via the ZEW databases.
German Central Bank;Statistics on securities investments: Support of data preparation through integration of machine learning procedures 20;Classification;;Prototype;Random Forest;Python;A Random Forest algorithm learns to mark data reported from employee decisions as incorrect and to make predictions about the probability of error.
German Central Bank;Record Linkage in FDSZ 21;Classification;;Prototypes;Random Forest;Python, SAS;Identification of units from various internal and external company databases for the creation of linked company data for research purposes.
German Central Bank;Combination of statistical tests for the existence of seasonal patterns in macroeconom ic time series 22;Classification;;Project;Random Forest, Conditional Random Forest;R;The random forest algorithm, which can be assigned to machine learning, is repeatedly one of the best forecasting and classification methods. At the same time, measures exist for determining the importance of predictors. Thus, random forests can be used to combine the results of different seasonal tests and quantify the influence of each test on the final classification decision and thus the information content of each test.
German Central Bank;Classification of economic activities for sole proprietor- ships 23;Classification;;Implemented;Artificial neural backpropagation network with an error learning sequence from Support Vector Machine and Random Forest. (previously Logit Backward Selection);R (formerly Stata);Economic activities are provided by various data providers in the non-ficial individual accounts statistics of the Deutsche Bundesbank. The quality of these sources varies over time as well as in cross-section. A poor allocation of the branch of economic activity can lead to distortions in the company accounts statistics, in particular by holding companies.  As holding companies differ from other companies in their ficial structure, it is classified whether a company is a holding company or not. Doubtful cases are then examined manually.
IAB & University of Mannheim;New methods for professional coding 25;Classification;Classification with several classes;Under development;Comparison of different algorithms, Stacking, Boosting;R;Professional code refers to the assignment of free text answers from surveys to official professional classifications. The generation of proposals for manual coding has so far been partly automatic, based on a list of job designations and string matching algorithms. The project is testing whether training data from previous surveys can be used as an alternative to generate better proposals. Furthermore, the suggestions should be displayed directly during the interview so that the interviewees can choose the most suitable category themselves.
IAB;Correction of training information in administrative data;Classification;Classification with several classes;Under development;Decision Trees, Random Forest, SVM, Boosting, Ensembles, Stacking;R;Within the framework of the project, a data-driven procedure for the correction of educational information in administrative individual data is to be developed and compared with current deterministic methods.
IAB;Prediction of duration in unemploymen t and evaluation of placement measures on the basis of a field experiment with machine learning methods26;Classification;Regression and classification;Ongoing DFG project;Decision Trees, Random Forest, SVM, Boosting, Ensembles, Stacking;R;Within the framework of the DFG project, context-related possibilities for predicting unemployment with machine learning will be tested and used to evaluate the effects of a field experiment.
IAB;Estimation of economic activities using CART procedures;Classification;Classification with several classes;Under development;Decision Trees;R;Regular changes in the classification of economic activities cause problems when evaluating over longer periods of time. As part of the project, individual classifications will be updated for the IAB's operational history panel over the entire period of the panel, so that evaluations will be possible on a consistent classification.
IAB FB C1 and Bristol University;Prediction of unemploy- ment duration 27;Classification;Classification and prediction;Productive operation;Decision Trees, Logit, Lasso, SVM;R;The aim of the project is to predict unemployment by means of machine learning methods and to investigate already conducted experiments on different aspects of assignment processes to heterogeneous treatment effects, also with reference to machine learning methods.
IAB;Imputation of missing information on working time;Classification;;Completed;Classification Trees, Cross Validation;R;As a result of the change in the activity characteristic of the social security declarations (DEÃƒÅ“V), the full-time/part-time specification was missing in the employee declarations in 2011 and 2012. They were imputed with the help of classification trees.
Federal Office for Migration and Refugees;Profile analysis;Classification;Aggregation and classification of text passages;Development of a pilot system;Semantic text analysis;Watson Explorer (WEX);With the implementation of a proof of concept and the subsequent development of a pilot system, the profile analysis project will test machine learning methods at the Federal Office for Migration and Refugees for the first time. A semantic text analysis of the hearing records in the context of the asylum procedure is provided. The aim is to highlight relevant text passages that point to safety-relevant information and to classify them according to given safety criteria. The analysis results are prepared in a user-friendly way and thus support the responsible clerks in fulfilling the BAMF's reporting obligation.
GESIS - Leibniz Institute for the Social Sciences;Towards Quantifying Sampling Bias in Network Inference30;Classification;Relational Classification;Research publication;Bayes + Relaxation + Collective Inference;Python;"Abstract: ""Relational inference leverages relationships between entities and links in a network to infer information about the network from a small sample. This method is often used when global information about the network is not available or difficult to obtain. However, how reliable is inference from a small labelled sample? How should the network be sampled, and what effect does it have on inference error? How does the structure of the network impact the sampling strategy? We address these questions by systematically examining how network sampling strategy and sample size affect accuracy of relational inference in networks. To this end, we generate a family of synthetic networks where nodes have a binary attribute and a tunable level of homophily. As expected, we find that in heterophilic networks, we can obtain good accuracy when only small samples of the network are initially labelled, regardless of the sampling strategy. Surprisingly, this is not the case for homophilic networks, and sampling strategies that work well in heterophilic networks lead to large inference errors. These findings suggest that the impact of network structure on relational classification is more complex than previously thought."""
GESIS - Leibniz Institute for the Social Sciences;Enriching ontologies with encyclopedic background knowledge for document indexing35;Classification;Document classification;Research publication;LLDA, SVM;Scala, Python;Using encyclopedic background knowledge for enriching domain- specific ontologies for document classification
GESIS - Leibniz Institute for the Social Sciences;Why we read Wikipedia38;Classification;;Research publication;Gradient Boosting;Python, Spark;"Abstract: ""Wikipedia is one of the most popular sites on the Web, with millions of users relying on it to satisfy a broad range of information needs every day. Although it is crucial to understand what exactly these needs are in order to be able to meet them, little is currently known about why users visit Wikipedia. The goal of this paper is to fill this gap by combining a survey of Wikipedia readers with a log-based analysis of user activity. Based on an initial series of user surveys, we build a taxonomy of Wikipedia use cases along several dimensions, capturing users' motivations to visit Wikipedia, the depth of knowledge they are seeking, and their knowledge of the topic of interest prior to visiting Wikipedia. Then, we quantify the prevalence of these use cases via a large-scale user survey conducted on live Wikipedia with almost 30,000 responses. Our analyses highlight the variety of factors driving users to Wikipedia, [...]. Finally, we match survey responses to the respondents' digital traces in Wikipedia's server logs, enabling the discovery of behavioral patterns associated with specific use cases. For instance, we observe long and fast-paced page sequences across topics for users who are bored or exploring randomly, whereas those using Wikipedia for work or school spend more time on individual articles focused on topics such as science. Our findings advance our understanding of reader motivations and behavior on Wikipedia and can have implications for developers aiming to improve Wikipedia's user experience, editors striving to cater to their readers' needs, third-party services (such as search engines) providing access to Wikipedia content, and researchers aiming to build tools such as recommendation engines."""
GESIS - Leibniz Institute for the Social Sciences;Text Categorization for Deriving the Application Quality in Enterprises Using Ticketing Systems42;Classification;Text classification;Research publication;SVM, Decision Tree and others;Java;"Abstract: ""TodayÃ¢â‚¬â„¢s enterprise services and business applications are often centralized in a small number of data centers. Employees located at branches and side offices access the computing infrastructure via the internet using thin client architectures. The task to provide a good application quality to the employers using a multitude of different applications and access networks has thus become complex. Enterprises have to be able to identify resource bottlenecks and applications with a poor performance quickly to take appropriate countermeasures and enable a good application quality for their employees. Ticketing systems within an enterprise use large databases for collecting complaints and problems of the users over a long period of time and thus are an interesting starting point to identify performance problems. However, manual categorization of tickets comes with a high workload.In this paper, we analyze in a case study the applicability of supervised learning algorithms for the automatic identification of relevant tickets, i.e., tickets indicating problematic applications. In that regard, we evaluate different classification algorithms using 12,000 manually annotated tickets accumulated in July 2013 at the ticketing system of a nation-wide operating enterprise. In addition to traditional machine learning metrics, we also analyze the performance of the different classifiers on business-relevant metrics."""
 Central Statistical Bureau of Latvia                ; Number of population and key demographic indicators 44             ;Classification;; Productive                 ; Logistic Regression (GLM) is used in production. Stochastic Gradient Boosting (GBM), Support Vector Machines (SVM), Regularized Discrimit Analysis (RDA), Multi-Layer Perceptron (MLP), Radial Basis Function Network (RBF) were tested during the implementation stage.; R (data.table)                 ;                  
 Central Statistics Office of Ireland   ; Automatic coding via open-source indexing utility ;Classification; Multi-class classification   ; Development    ;     ; Apache Lucene / Python   ; An automatic coding system for Classification of Individual Consumption by Purpose (COICOP) assignment for their Household Budget Survey, using previously coded records as training data. Their method is based on the open-source indexing and searching tool Apache Lucene (http://lucene.apache.org).
 Federal Statistical Office of Switzerland ; Modelling of the non- response mechanism;Classification; Binary classification of response homogeneity groups; Productive   ; CHAID   ; SAS   ; Classification trees are used to model the behaviour of the non- respondents in order to diminish non-response bias in the results.  
 Federal Statistical Office of Switzerland   ; Detection of suspicious responses   ;Classification;; Test     ; Generalized boosted models, Random Forest, Neural networks, Naive Bayes, Tree algorithms, ...; R     ; Several machine learning algorithms are tested to detect anomalies in the data. Detected units are contacted to check the data again. These methods are applied in a field where no or very few edit rules are available.  
 Federal Statistical Office of Switzerland  ; Turnover breakdown from grouped answers to the enterprises;Classification;; Test    ; Random Forest    ; R    ; This project is at its beginning. It is planned to use random forests to learn from the Turnover statistics and to apply it to the units not in the Turnover statistics. There is no other data available to breakdown grouped VAT data. 
 Federal Statistical Office of Switzerland ; Automatiza- tion of the NOGA (Swiss NACE) coding;Classification;; Test   ; Several   ; R   ; This project is at its very beginning. It is planned to test several machine learning algorithms which are not yet fixed.  
 Federal Statistical Office of Switzerland   ; Automatiza- tion of land cover and land use codes based on aerial images;Classification;; Test     ; CNN     ; R/Python     ; This project is at its beginning. It is planned to use convolutional neural networks for coding or for change detection.    
 Hungarian Central Statistical Office Institut national de la statistique et des ÃƒÂ©tudes ÃƒÂ©conomiques (INSEE)        ; Tax evader detection46 Detecting wages/paid hours anomalies in employer payroll declaration statistical databases    ;Classification; Classification  Non supervised algorithms           ; Experiment  Ongoing experiment           ; k-NN  Fuzzy associations, Isolation Forest, local outliers factors          ;   R, Python            ; Detecting self-employed proprietors who are tax evaders  The Annual Declaration of Social Data (Ã¢â‚¬Å“dÃƒÂ©claration annuelle de donnÃƒÂ©es socialesÃ¢â‚¬Â, DADS), mandatory fulfilled each year by each employer and to which reported individual wage-earner information is transmitted to fiscal and social services for payroll and tax purposes as well as for calculating social security wage-earners rights (e.g., pensions), has been replaced since 2016 by a monthly Nominative Social Declaration information. This change of sources completely modifies the national statistical service of information on employment and wages that relies on, and provides the opportunity to rethink the automatic anomaly detection process implemented in the statistical production line. The experimental project tests different machine learning-based algorithms for anomaly detection of net and gross wages and related paid hours.
 Institut national de la statistique et des ÃƒÂ©tudes ÃƒÂ©conomiques (INSEE) and Statistical office of the Interior Ministry; Identify the cases of intra- family violence in the complaint filings  ;Classification; Text mining, classification      ; Stand by       ; LDA, Random Forest       ; R       ; The purpose of this study is to identify for each complaint, whether it can be considered as a intra-family violence or not,  by exploiting contextual information filled out in a free-format box together with standardized information. The experiment uses 3 millions of complaints from the Paris region and applies textual analysis and machine learning techniques  
Institut national de la statistique et des ÃƒÂ©tudes ÃƒÂ©conomiques (INSEE) and IPP- Paris School of Economics;Machine learning for predicting careers and wages for micro- simulation models;Classification;Multinomial classification;Ongoing experiment;Classification Trees, Random Forest, Boosting;R;"Modelling labour market trajectories is of crucial importance to study retirement behaviours, pension distribution, and ficial balances of retirement plans, especially in a pay-as-you-go system. We explore two margins of improvement for microsimulation of labour market trajectories: the use of non-parametric methods (random forests and boosted trees) and a discretized modelling of individual unobserved heterogeneity. We use administrative data from French complementary pension system in the private sector to design and test our simulation method; those data lack variables related to education level, marriage and family. Performance of models is assessed regarding both cross-sectional indicators and indicators of trajectory consistency. By doing so, we ensure that the techniques we develop reproduce the inner individual dynamics, a real challenge when simulating pension levels. In line with the needs expressed in reviews of existing models, we propose a simple framework for a systemic evaluation of models' performance."
National Institute of Statistics Romania;Action plan for EU-SILC improvements;Classification;Poverty indicators;Productive;Random Forest;R;The data matching methods have been used in order to increase the quality of EUSILC sample bringing together information from different data sources: sample survey and administrative registers.
National Institute of Statistics Romania;Modeling the potential human capital on the labor market48;Classification;;"Actually no ML; experiment";Logistic Regression;R;Creating the profile of two categories of potential human capital by modelling the relationship between economically inactive persons who are seeking for a job, but are not immediately available to start working, respectively economically inactive persons who are not seeking for a job, but are immediately available to start working, and some socio-economic predictors. The aim is to identify the impediments which determine inactive people not to become active on the labour market.
National Statistics Center, Japan;Supervised multiclass classifier for an autocoding for the Family Income and Expenditure survey49;Classification;Multiple classification;Experiment;NaÃƒÂ¯ve Bayes;Pearl / R;Multiclass classifier that can classify Japanese short text descriptions according to their corresponding classification codes has been developed for the Family Income and Expenditure survey in Japan. The concept of the naÃƒÂ¯ve Bayes classifier is borrowed for the algorithm of the classifier. The classifier is also applicable to English text descriptions and other classifications tasks.
 OECD        ; Algorithms and Collusion50      ;Classification;; Experiment        ; Several methods        ;         ; The combination of data with technologically advanced tools such as pricing algorithms and machine learning is increasingly changing the competitive landscape in the digital markets. There is a growing number of firms using computer algorithms to improve their pricing models, customise services and predict market trends, which could generate efficiencies. However, the widespread usage of algorithms could also pose possible anti-competitive effects by making it easier for firms to achieve and sustain collusion without any formal agreement or human interaction.
 STATEC (Luxembourg)    ; Scanner Data     ;Classification;; Productive     ; MLR     ; Solr / Java / Talend    ; Machine Learning Ranking (MLR) is used in the Scanner Data project to classify the individual items into COICOP (Classification of individual consumption according to purpose), which is the standard classification used for compiling a CPI. It allows to use a larger sets of incoming data without increasing costs of manuel processing.
 STATEC (Luxembourg)        ; Business Enterprise Research and Development (BERD)     ;Classification;; Productive         ; Model Stacking         ; KNIME, R         ; An in-house developed ensemble classifier assesses for each survey respondent the probability of performing intra-mural R&D activities during the reference year. The probability is conditional on the available data, which includes current and past survey data (including unstructured text) as well as administrative sources. The model results are used in the survey data validation process to spot item non-response and inaccurate responses on the intra-mural R&D variables. Such respondents are then individually contacted by the statistical analysts, if necessary. Albeit the use of an ensemble classifier, the model results remain fully interpretable.
 Statistics Austria   ; Estimating AROPE for the Austrian rich frame53;Classification; Estimation/Classification  ; Productive   ; Boosting Trees Algorithm  ; R   ;Arope = At risk of poverty or social exclusion
 Statistics Belgium    ; Predicting the NACE code of a job vacancy  ;Classification; Binary classification    ; Test    ; SVM,    ; R (RtxtTools)    ; Machine learning is used to predict the NACE code of a job vacancy based on the job description. We use administrative databases (from national jobs portals) to model the link between words in the description and the NACE code. We expect to apply this model to scrap job vacancies from internet job portals in Belgium.
Statistics Canada;Consumer Prices scanner data use;Classification;;In production parallel run;SVM;python;Consumer Prices: retail scanner data classification to the Consumer Price Index (CPI) commodities classification, used to suggest CPI product substitutions. Currently, in production parallel run.
Statistics Canada;Retail scanner data use for Monthly retail trade survey and Quarterly retail commodity survey;Classification;;Transitioning to production;XGBoost linear, with bag of words character n-grams model;R;Machine learning text classification is used to obtain the NAPCS code of each product sold within the retail scanner data, and obtain aggregate sales for each NAPCS, aggregate sales by area/ postal code. Proof of Concept (PoC) completed.
Statistics Canada;Business Activity, Expenditure and Output (BAEO) survey comments text mining;Classification;;Experiment completed;Linear SVM, with bag of words model;R;The BAEO survey receives close to 9000 comments. ML was used to classify the comments into 8 action categories.
Statistics Canada;Payments data feasibility project;Classification;;At experimentation stage;SVM;R;ML is used to classify the payment transactions into standard statistical classification concepts (NAICS, COICOP, etc). The projectÃ¢â‚¬â„¢s goal is to determine if the data can be used to produce information related to retail sales, household consumption, digital transactions, and tourism statistics. ML might be also used for imputation of misisng values.
Statistics Canada;Transport statistics: Trucking Commodity Origin and Destination Survey (TCOD);Classification;Text classification, image classification, predictive modelling for missing information based on auxiliary data, record linkage;At experimentation stage;recently started;R, Python;ML will be used to classify the electronically reported data. In the context of the TCOD survey redesign, the use of auxiliary sources such as GPS data, satellite imagery is evaluated as a new source for trucking data analysis, including linkage to a specific business on the BR.
Statistics Canada;Harvesting key data on causes of death from narrative descriptions;Classification;Classification;"Exploration part 1 completed (promising approach with limited success due to weak training data); Literature review completed for future exploration";Various (SVM, NN, Adabost NaÃƒÂ¯ve Bayes);Python;"Harvesting key data on causes of death and abuse from narrative descriptions Exploring narrative descriptions to harvest statistical information (cause of death in coronersÃ¢â‚¬â„¢ reports; abuse case in social workersÃ¢â‚¬â„¢ narrative description) A machine learning application is being used to mine more rapidly and efficiently the unstructured narratives that coroners include in their reports and that detail the circumstances of the deaths. These narratives are included in our Canadian Coroners and Medical Examiners Database (CCMED). Its first goal is to identify opioid- related deaths. In the longer-term, it is hoped that machine learning/Artificial Intelligence would permit to rapidly recognize any patterns that would point to another crisis or specific circumstances that affect many investigated death cases."
 Statistics Canada      ; Study of comments submitted during the 2016 Census content consultation;Classification; Key term identification and binary classification    ; Productive      ; Natural Language Processing     ; SAS JMP      ; Used text mining software to analyze over 1.1 million comments compiled from the 2016 Census content consultation to inform possible content and questionnaire changes for 2021.    
 Statistics Canada  ; Census and others ;Classification;Classification; Exploration  ; Unsupervised ML to cluster comments ; SAS Enterprise Miner ; Exploring information provided in comments box in the Census with focus on non-binary gender self-identification in open text/comment box
 Statistics Canada        ; Creating synthetic data for micro- simulation     ;Classification;; Idea to start in FY 2018       ; Likely K Nearest Neighbours       ; R, knnnn package        ; Microsimulation models require complete data. Currently in the Population Health Microsimulation Model (POHEM) we do not model measured data such as that collected Canadian Health Measures Survey (CHMS). Having measured data in POHEM is a desirable attribute if the model is to be used for evidence-based policy analysis around cardiovascular disease and other chronic diseases. AI solution: Use AI/machine learning techniques to match data from the CHMS to the Canadian Community Health Survey (CCHS) in order to initialize a starting POHEM population with measured health data.
 Statistics Canada     ; Automated extraction of features for record-linkage  ;Classification;; Initial exploration     ; Supervised, unsupervised, dimension reduction techniques (e.g. PCA); SAS     ; The goal is to automate the selection of features for record-linkage. Currently these features are selected manually based on expert knowledge.   
 Statistics Canada      ; Machine Learning for record linkage    ;Classification; Binary classification      ; Exploration      ; SVM, Neural network, Supervised Logistic    ; SAS EM      ; Similarities metrics such as Jaro, Jaro-Winkler, Fuzzy Winkler, Fuzzy Jaro are developed in G-Link and ready to be used by Machine Learning methods outside of G-Link. We are exploring the use of the SAS enterprise Miner software. In this way, Statistics Canada is creating an opportunity to examine and compare the Fellegi-Sunter classifier with alternative methods (SVM, neural networks etc. )
Statistics Canada;NAICS/NOC autocoder;Classification;;Refining the model for increased accuracy, to be implemented in Python;Bag of words and statistical classifier;Pearl, Python;Automatic data classification (various classifications including occupation and industry)
Statistics Canada;Exploration of machine learning to identify driving under the influence by type of substance;Classification;;Idea;TBD;TBD;Social media scrapping for estimating the prevalence of driving under the influence by type of substance.
Statistics Finland;Machine reading accident reports;Classification;Binary classification;Productive;tf-idf + Logistic Regression;Python;Free-text road traffic accident reports from the Police are classified to those which caused personal injuries and those which did not
Statistics Finland;Automatic coding of industry and occupation56;Classification;Multi-class classification;Development;Random Forest;Python;Random forest classifiers are used to automatically classify Finnish Labour Force Survey respondents to correct industry and occupation (NACE, ISCO) based on combined register and survey data
Statistics Iceland;Assignment of fine-grained product ids based on product descriptions;Classification;;In review;Random Forest;Python;
Statistics Netherlands;Predicting moving behavior;Classification;Binary classification, can be expanded to multinomial classification;Experiment;Random Forest;R;Random forests are used to predict moving behavior of persons from registered life-history events. Predictions can potentially replace a survey questionnaire and thus contribute to shorter questionnaires and reduce survey fatigue.
Statistics Netherlands;URL retrieval Enterprises58;Classification;Binary classification;Production;Decision Tree / Random Forest;Node + Python;Retrieval of URLs using Google custom search, a training set of enterprises with known URLs and a list of enterprises with administrative infomation. For Eommerce detection, social media detection and identifying foreign companies.
Statistics Netherlands;Enterprise classifier21;Classification;;Test;Decision Tree / Random Forest;Node + Python;Prediction of website use, ecommerce detection, social media detection.
 Statistics Netherlands      ; Classification of products into product categories for the CPI   ;Classification; Multiclass classification      ; Idea       ; Random Forest       ; Python       ; The Random Forest algorithm has been extended with active and online learning techniques to classify online products (scraped from e.g. webshops) into product categories. The algorithm aims to keep the training set as small as possible by re-using training items from previous months. Only when quality gets too low, additional training items from the current month are added to the training set, and we then try to use those items that result in the biggest improvement in quality.
 Statistics Netherlands, in collaboration with Tenforce ; Classification of supermarket products for the CPI;Classification; Multiclass classification   ; Test    ; SVM / Random Forest   ; Python    ; Research into the use of Support Vector Machines and Random Forest to classify supermarket (food) items into LCOICOP categories using scanner data  
 Statistics Netherlands                   ; Adaptive data collection at Statistics Netherlands with an application to the Health Survey59             ;Classification;Classification; Productive                    ; Classification Tree                    ; R                    ; Challenges that surveys are facing are increasing data collection costs and declining budgets. During the past years, many surveys at Statistics Netherlands were redesigned to reduce cost and to increase or maintain response rates. Currently, alternative approaches are investigated to produce more accurate estimates within the same budget. Adaptive data collection is proposed for achieving this goal.  Research into the effect of reducing face to face observation in mixed mode surveys on quality and costs was carried out in 2017. Reducing face to face observation can be done in various ways. It can be done through random selection, but also through stratified selection of nonrespondents eligible for face to face follow-up. By using the latter method, nonresponse bias can potentially be reduced. The key decisions to be made are how to divide the population into strata and how to compute the allocation probabilities for face to face follow-up in the different strata. In this presentation the adaptive data collection is elaborated for the Health Survey as it is conducted by Statistics Netherlands since 2018. Attention is paid to the choice of the strata, the choice of the mixed mode observation strategy, the optimization problem with corresponding constraints and the effect of the adaptive data collection on most important survey estimates.
 Statistics Netherlands ; Cyber Security  ;Classification; Binary classification  ; Experiment  ; SVM  ; Python  ; Predict the number of cyber security companies in The Hague area, based on the company websites. We use webscraping, textming and machine learning techniques.
 Statistics Netherlands     ; Automated classification of sustainable companies based on machine learning;Classification; Binary classification      ; Experiment      ; Yet unknown      ; Python      ; Predict the number of companies active in the field of specific SDGs based on the company websites. We use webscraping, textming and machine learning techniques.    
 Statistics Netherlands   ; Cross-Border Internet Purchases at EU webshops61;Classification; Binary classification    ; Productive (beta)    ; Semi-Automated Machine Learning   ; Python    ; Semi-automated machine learning to predict whether an EU company sells goods to Dutch consumers through webshops.   
 Statistics Norway       ; Exploration on Random Forest for editing purposes in register based salary statistics;Classification;;        ; Random Forest       ; R       ;        
 Statistics Portugal   ; Big Data ESSNet  ;Classification; Multiclass classification  ; Test   ; SVM (linear kernel)   ; Python (SciKit- Learn library in a Jupyter Notebook environment);    
 Statistics Portugal   ; Big Data ESSNet  ;Classification; Multiclass classification  ; Test   ; Perceptron (linear)   ; Python (SciKit- Learn library in a Jupyter Notebook environment);    
 Statistics Portugal    ; Big Data ESSNet   ;Classification; Multiclass classification   ; Test    ; Neural Network Model for language identification  ; R Package Ã¢â‚¬Å“cld3Ã¢â‚¬Â (Google's Compact Language Detector 3);     
 Statistics Spain (INE)  ; Selective Editing of Qualitative Variables;Classification; Binary classification   ; Planning stage   ; Random Forest, SVMs, Logistic Regression, kNN Regression; R   ; Different classification techniques are to be explored to classify influential/non-influential units in the optimization approach to selective editing of qualitative variables under development at Statistics Spain (INE)
 Statistics Sweden       ; Essnet big data WP2 - Web scraping enterprise characteristics - Use case of Job advertisement;Classification; Binary classification       ; Under development      ; SVC, Decision Tree, Naive Bayes, Keras sequential NN   ; Python       ;        
Statistics Sweden;Essnet big data WP2 - Web scraping enterprise characteristics - Use case of NACE;Classification;Multilabel classification;Under development;Keras sequential NN;Python;
Statistics Sweden;Automatic coding of occupation title using machine learning methods;Classification;Binary classification;Implementation in production;k Nearest Neigbour;C# and R;
Stats NZ;Assignment of geographic region to individuals;Classification;;Test;Decision Tree;R;Decision Trees and random forest methods used to assign the correct Territorial Authority to individuals given a range of administrative data sources
Stats NZ;Classification of Building Consents with Natural Language Processing;Classification;Multi-level classification;Tested, not yet in production;Supervised Learning: Generalised Linear Model;R;A generalised linear model has been trained on historical consents data to perform classification of building consents into multiple classes. The model uses a bag of words approach, and is currently being brought into production.
Stats NZ;Classification of building consents;Classification;;Experiment;Generalised Linear Model using vectorised n-grams;R (glmnet and text2vec);We used manually coded data to train a model that categorises building consents based on a free text field (job description, as supplied by the applicant). We predict several variables, including building type (which has 29 possible values).
Stats NZ;Coding of industry classification;Classification;;Idea;;;Early days in thinking
Stats NZ;Automatic coding of census variables via Support Vector Machines;Classification;Multi-class classification;Experiment;SVM;;Investigation of the potential of using Support Vector Machines (SVM) to improve coding of item responses in their Census. They applied SVM to code the variables Occupation and Post-school Qualification, using two disjoint sets of observations, each of size 10,000, from Census 2013 data for training and testing.
Stats NZ;Imputation via Classification and Regression Trees;Classification;Classification / imputation;Experiment;Decision Tree;;Investigation in the use of CART to predict two binary variables based on Census 2013 data. The binary variables were 1. the missingness of the income variable, and 2. the response to the question of whether the respondent has moved since the previous census. Results of this investigation are being evaluated.
U.S. Bureau of Labor Statistics;Automatic coding of worker injury narratives for the Survey of Occupational Injuries and Illnesses64;Classification;Multinomial text classification;Production;Regularized Logistic Regression, Deep Neural Networks;Python, Scikit- learn, Tensorflow, Keras;Each year the Survey of Occupational Injuries and Illnesses (SOII) collects hundreds of thousands of written narratives describing work related injuries and illnesses. In order to produce statistics from this information each of these narratives receives 6 of several thousand possible codes to indicate the occupation of the worker and various characteristics of the incident. To improve the consistency and efficiency of this manual effort BLS developed and evaluated a variety of automated approaches, settling initially on regularized multinomial logistic regression. BLS found automated coding with regularized logistic regression produced more accurate coding than trained human coders, even after the human codes had the benefit of several layers of review. As a result BLS began using this technique to automatically assign codes starting with 2014 data. BLS is now automatically assigning nearly two-thirds of all SOII codes and has recently developed new deep neural network models that provide even better performance. These neural network models are currently used to identify suspicious codes for review, and are likely to be deployed for production autocoding later this year.
U.S. Bureau of Labor Statistics;Automatic coding and review of occupation narratives for the Occupational Requirements Survey;Classification;Multinomial text classification;Research;Regularized Logistic Regression;Python, Scikit- learn;One of the key data elements collected by the Occupational Requirements Survey (ORS) is the occupation classification, which is recorded in part, in text format. To more efficiently and effectively validate this data BLS is investigating the application of the same machine learning techniques now successfully being used for the SOII to assist in the review and validation of ORS occupation data. Initial results show promise. BLS will also be investigating whether occupation data from other surveys (like the SOII, and the National Compensation Survey), can be used to improve the performance of the ORS automatic reviewing system.
U.S. Bureau of Labor Statistics;Automatic extraction of benefits information from Summary of Benefits and Coverage documents.;Classification;Text classification, information extraction;Research;Random Forest;Python, Scikit- learn;"Health insurance benefits are an important component of worker's compensation and are often described in a semi-structured document called the ""Summary of Benefits and Coverage"". This project aims to use machine learning to automatically extract benefits information from these documents with the goal of eventually using this information to augment the National Compensation Survey. Initial results demonstrate that we can automatically extract some of this information at very high accuracy."
U.S. Bureau of Labor Statistics;Analysis of nonresponse to the Occupational Employment Statistics (OES) Survey66;Classification;Model assisted estimation;Research;Regression Trees;R (mase package);Auxiliary information can increase the efficiency of survey estimators through an assisting model when the model captures some of the relationship between the auxiliary data and the study variables. Despite their superior properties, model-assisted estimators are rarely used in anything but their simplest form by statistical agencies to produce official statistics. This is due to the fact that the more complicated models that have been used in model-assisted estimation are often ill suited to the available auxiliary data. Under a model-assisted framework, we propose a regression tree estimator for a finite population total. Regression tree models are adept at handling the type of auxiliary data usually available in the sampling frame and provide a model that is easy to explain and justify. The estimator can be viewed as a post-stratification estimator where the post-strata are automatically selected by the recursive partitioning algorithm of the regression tree. We establish consistency of the regression tree estimator and a variance estimator, along with asymptotic normality of the regression tree estimator. We then compare the performance of our estimator and the coverage of the confidence intervals using our variance estimator to other survey estimators using US Bureau of Labor Statistics Occupational Employment Statistics Survey data.
U.S. Census Bureau;Using an Autocoder to Code Industry and Occupation in the American Community Survey 68;Classification;Multi-class classification;Test;Logistic Regression;SAS;Every year the American Community Survey (ACS) collects industry and occupation data on nearly 2.5 million individuals. The text write- in information must then be coded, or converted to an industry or occupation numeric category code.
 U.S. Department of Agriculture NASS     ; Informing Sample Design for the Census of Agriculture   ;Classification; Developing response propensity scores to inform sampling design    ; The response propensity scores have been used in developing a sampling plan for non-respondents. Data collection is in progress.; Random Forest with Boosting      ; SAS JMP       ; Random forests with boosting were applied to predict the probability of the non-respondents after mailing to respond to the Census of Agriculture. The predicted probabilities were used as one of the stratifying variables in the sample design of non-respondents.    
U.S. Department of Agriculture NASS;non- respondent prediction70;Classification;;Experiment;Decision Tree;SAS;Non-response adjustment for the Census of Agriculture. Farms within each state in the US were partitioned into groups of Ã¢â‚¬Å“homogeneous response propensityÃ¢â‚¬Â using a classification tree model. Non- response adjustments were performed within each such group based on the response rate within that group.
U.S. Department of Agriculture NASS;Analysis of reporting errors71;Classification;;Experiment;Decision Tree;SAS;Prediction of respondents likely to make reporting errors based on sampling frame data. Results of this analysis could suggest reasons for the reporting errors, types of respondents to be included in questionnaire testing, and editing strategies after data collection.
RKI / P4;Application of machine learning methods in RKI health monitoring (KiGGS)16;Clustering;Clustering, binary and multi-class classification;Experiment;Cluster methods, Decision Trees, Neural Networks;Python;As part of the KiGGS study, the RKI collected around 4000 variables on the health of over 17,000 children and young adults. Due to the size and heterogeneity of the data set, classical statistical methods sometimes reach conceptual limits. As a pilot project for the use of machine learning methods in public health monitoring, this project is intended to show how novel methods of machine learning can be used in the work of the RKI. Various methods will be tested to identify structures and correlations in the data and to predict the occurrence of chronic diseases.
IAB FB B2;Typification of labour market regions (comparison types SGB III / SGB II) 24;Clustering;;Productive operation;Clustering according to Ward / k-Means algorithm;Stata;In the second stage of the typification process, employment agency or job centre districts with similar regional labour market characteristics are clustered through the use of Unsupervised Learning. The Ward method is combined with a k-Means algorithm.
GESIS - Leibniz Institute for the Social Sciences;How Users Explore Ontologies on the Web: A Study of NCBO's BioPortal Usage Logs31;Clustering;Clustering, dimensionality reduction;Research publication;k-Means + PCA;Python, R;"Abstract: ""Ontologies in the biomedical domain are numerous, highly specialized and very expensive to develop. Thus, a crucial prerequisite for ontology adoption and reuse is effective support for exploring and finding existing ontologies. Towards that goal, the National Center for Biomedical Ontology (NCBO) has developed BioPortal---an online repository containing more than 500 biomedical ontologies. In 2016, BioPortal represents one of the largest portals for exploration of semantic biomedical vocabularies and terminologies, which is used by many researchers and practitioners. While usage of this portal is high, we know very little about how exactly users search and explore ontologies and what kind of usage patterns or user groups exist in the first place. Deeper insights into user behavior on such portals can provide valuable information to devise strategies for a better support of users in exploring and finding existing ontologies, and thereby enable better ontology reuse. To that end, we study and group users according to their browsing behavior on BioPortal and use data mining techniques to characterize and compare exploration strategies across ontologies. In particular, we were able to identify seven distinct browsing types, all relying on different functionality provided by BioPortal. For example, Search Explorers extensively use the search functionality while Ontology Tree Explorers mainly rely on the class hierarchy for exploring ontologies. Further, we show that specific characteristics of ontologies influence the way users explore and interact with the website. Our results may guide the development of more user-oriented systems for ontology exploration on the Web."""
GESIS - Leibniz Institute for the Social Sciences;Practical collapsed stochastic variational inference for the HDP32;Clustering;Bayesian non- parametric mixed- membership clustering;Research publication;PCSVB0;Juliet;In this work we explore a collapsed stochastic variational Bayes inference for the Hierarchical Dirichlet process (HDP). The proposed online algorithm is easy to implement and accounts for the inference of hyper-parameters.
GESIS - Leibniz Institute for the Social Sciences;Discovering and Characterizing Mobility Patterns in Urban Spaces: A Study of Manhattan Taxi Data40;Clustering;;Research publication;Tensor Factorization;Python;"Abstract: ""Nowadays, human movement in urban spaces can be traced digitallyin many cases. It can be observed that movement patternsare not constant, but vary across time and space. In this work,we characterize such spatio-temporal patterns with an innovativecombination of two separate approaches that have been utilized forstudying human mobility in the past. First, by using non- negativetensor factorization (NTF), we are able to cluster human behaviorbased on spatio-temporal dimensions. Second, for characterizingthese clusters, we propose to use HypTrails, a Bayesian approachfor expressing and comparing hypotheses about human trails. Toformalize hypotheses, we utilize publicly available Web data (i.e.,Foursquare and census data). By studying taxi data in Manhattan,we can discover and characterize human mobility patterns that cannotbe identified in a collective analysis. As one example, we finda group of taxi rides that end at locations with a high number ofparty venues on weekend nights. Our findings argue for a morefine-grained analysis of human mobility in order to make informeddecisions for e.g., enhancing urban structures, tailored traffic controland location-based recommender systems."""
Statistics Netherlands;;Clustering;;Research;k-Means;;Clustering and classification of SMEs (small and medium enterprises) based on website descriptions
U.S. Bureau of Labor Statistics;Text Analysis of Interviewer Notes;Clustering;"Clustering of 
interviewer notes";Research;Model-Based Clustering, k-Means Clustering, Bayesian Hierarchical Clustering;MATLAB and R;Using text analysis and clustering (unsupervised learning) to extract information and themes from survey interviewer notes, based on data from the Consumer Expenditure Survey. We also connected the themes from interviewer notes with sample unit behavior as captured in the Contact History Instrument.
 Federal Statistical Office of Switzerland  ;" Clustering of the ""careers"" in the social security system";Clustering    ;; Test    ; Several    ; R    ;" This project is at its beginning. It is planned to test whether it is possible to detect similar ""careers"" in the social security system automatically.  "
 ONS        ; Unsupervised document clustering with cluster topic identification 51   ;Clustering    ;; Experiment        ; Doc2vec        ;         ; This piece of work is inspired by a project the Office for National StatisticsÃ¢â‚¬â„¢ (ONS's) Big Data Team have been exploring with data extracted from Companies House. Medium- to large-sized businesses are required to submit a full accounts document to Companies House and within this document the businesses typically include a description of the function of the company. This is potentially useful information to help classify the business into its relevant UK Standard Industrial Classification 2007: UK SIC 2007 code, and may offer insight into emerging new topics in industry.
GESIS - Leibniz Institute for the Social Sciences;A System for Probabilistic Linking of Thesauri and Classification Systems37;Concept linking;;Research;PLL-TM;Julia, CML, D3;"Presents a system which creates and visualizes probabilistic semantic links between concepts in a thesaurus and classes in a
classification system."
Statistics Canada;Enterprise statistics;Data extraction;;At experimentation stage;NLP, Record Linking;R, Python;Web scraping for large enterprises to complement the survey data sources with on-line data (newsfeed, ficial reports, company Web sites) to enhance data coherence, improve profiling, prepare the Entreprise Portfolio Managers' visits to companies.
Statistics Canada;Web scraping to enhance the research and development survey frames;Data extraction;;At experimentation stage;NLP, Record Linking;R, Python;Web scraping is used to supplement the R&D survey data with on- line data to identify adequately the survey population, and develop complementary indicators for innovation.
Statistics Canada;Retail statistics;Data extraction;;At experimentation stage;NLP, Record Linking;Python;Web scraping and google map for retail store information
Hessian Statistical Office;Webscraping of enterprise websites 19;Data extraction, coherence checks;Binary classification;Test mode;Webscraping, graph-based neural networks;Java, R, MySql, Apache Spark;Web scraping of enterprise websites and machine learning to gain new digital data
Stats NZ;Derivation of edit rules;Editing;;Experiment;Association Analysis;;Investigation of the potential of using association analysis to derive additional edit rules to enhance the processing of census data.
Federal Statistical Office of Germany;Proof of Concept automated plausibility check (in the earnings statistics);Error detection;Error detection and imputation;Experiment;HoloClean (underlying probability model as factor graph, inference via Gibbs sampling);Python (PyTorch), Apache Spark, PostgreSQL;The use of the HoloClean software for automated plausibility checks of earnings statistics data is to be tested. HoloClean has an error and outlier detection module and learns a probability model based on several data sources that imputates (repairs) the erroneous data.
National Institute of Statistics Romania;Use of administrative data in business statistics;Imputation;;Experimental;Tree-Based Methods: Regression Trees, Random Forest, Boosting;R;Efficient integration of administrative data into the statistical process implies finding and resolving data quality issues. methods are used for imputation of the turnover variable for businesses from the value added tax (VAT) administrative data.
Statistics Denmark;Imputation of educational status for immigrants;Imputation;;;Random Forest;R (missForest);
Statistics Netherlands;;Imputation;;Research;Random Forest;;Imputation of economic data
Statistics Netherlands;Improvement of imputation by robust estimation and machine learning methods57;Imputation;Imputation of business statistics;Test;GBM (Gradient Boosting Machine);;Standard automatic imputation methods for business statistics, such as ratio-imputation are not always accurate. We are looking for improvements by using robust estimators and automated model building by machine learning techniques (gradient boosting machine).
Stats NZ;Determination of imputation matching variables;Imputation;Imputation / variable selection;Experiment;Random Forest;;Statistics New Zealand is redesigning the editing and imputation methodology of their Household Economic Survey (HES). Their current proposed methodology will use the Canadian Census Edit and Imputation System (CANCEIS). The imputation module of CANCEIS is based on the Nearest Neighbour Imputation Methodology, which requires user specification of a distance measure of pairs of units based on a number of Ã¢â‚¬Å“matching variablesÃ¢â‚¬Â as well as weights which defines the relative importance of these matching variables. The weight of a matching variable should reflect its strength as a predictor for the variables to be imputed. Statistics New Zealand has reported promising results in using Random Forests to select the set of matching variables for CANCEIS, as well as their weights.
Stats NZ;Creation of homogeneous imputation classes;Imputation;;Experiment;Decision Tree;R;Comparison of two methods (CART, predictive mean stratification) for creating homogeneous imputation classes.
 U.S. Department of Agriculture NASS   ; Informing imputation for the Census of Agriculture  ;Imputation; Developing response propensity scores and informing imputation ; A first imputation model has been implemented, and efforts are underway to improve it.; Random Forest with Boosting    ; SAS and SAS JMP     ; Random forests with boosting are used to inform imputation of the demographics section of the Census of Agriculture    
U.S. Department of Agriculture NASS;Machine learning for the Census of Agriculture;Imputation;Developing response propensity scores and informing imputation;The response propensity scores have been used in developing a sampling plan for non-respondnets. Currently, machine learning techniques are being used to inform imputation.;Random Forest with Boosting;SAS JMP;Machine learning methods are applied to computation needs in the production of Census of Agriculture, specifically sampling and imputation
 Statistics Austria ; Imputation52 ;Imputation ;; Productive ; kNN ; R ; In various surveys and also in projects with administrative data missing values should be imputed.
 Statistics Canada   ; R&D for imputation method ;Imputation ; Imputation   ; Exploration via hackathon planned in May 2018; Various   ; Various   ; Hackathon for advanced imputation methods using AI. Use use is imputation of a large admin files where adata can be entered for generic or detailed ficial item. When generic is used, data must be imputed for detailed item.
 Eurostat      ; Categorical data imputation via neural networks and Bayesian networks45;Imputation ;; Experiment      ; Logistic Regression, Neural Networks, Bayesian Networks    ; (SAS)      ; Eurostat compared imputation results for missing categorical data (voting intensions) based on two machine learning methods (neural networks and Bayesian networks) against one of the current prevailing statistical imputation methods (multiple imputation using logistic regression).  
U.S. Bureau of Labor Statistics;Occupational Employment Statistic (OES) Occupation Autocoding;Job title and other available information into one of many occupation codes;;Development and testing;LR using SGD;Python;Division of Occupational of Employment Statistics (OES) uses Multinomial Logistic Regression with Stochastic Gradient Descent to develop a model to assign occupation codes to job titles received with employer survey responses.
GESIS - Leibniz Institute for the Social Sciences;RDF Vocabulary Term Recommen- dation43;Learning To Rank;;Research publication;Various Learning To Rank algorithms from the RankLib library;RankLib Library (Java);"Abstract: ""Deciding which RDF vocabulary terms to use when modeling data as Linked Open Data (LOD) is far from trivial. In this paper, we propose TermPicker as a novel approach enabling vocabulary reuse by recommending vocabulary terms based on various features of a term. These features include the termÃ¢â‚¬â„¢s popularity, whether it is from an already used vocabulary, and the so-called schema-level pattern (SLP) feature that exploits which terms other data providers on the LOD cloud use to describe their data. We apply Learning To Rank to establish a ranking model for vocabulary terms based on the utilized features. The results show that using the SLP-feature improves the recommendation quality by 29Ã¢â‚¬â€œ36 % considering the Mean Average Precision and the Mean Reciprocal Rank at the first five positions compared to recommendations based on solely the termÃ¢â‚¬â„¢s popularity and whether it is from an already used vocabulary."""
 Statistics Austria ; Statistical matching;Matching;; Productive ; Random Forest, kNN ; R ; On the basis of common variables two data sets are matched (very similar to imputation.)
GESIS - Leibniz Institute for the Social Sciences;Predicting structured metadata from unstructured metadata34;Metadata prediction;;Research publication;LDA, SVM;Scala, Python;Framework to predict structured metadata terms from unstructured metadata for improving quality and quantity of metadata, using the Gene Expression Omnibus (GEO) microarray database
U.S. Bureau of Labor Statistics;Analysis of nonresponse to the Occupational Employment Statistics (OES) Survey65;Nonresponse propensity modeling;;Research;Regression Trees;R;To gain insight into how characteristics of an establishment are associated with nonresponse, a recursive partitioning algorithm is applied to the Occupational Employment Statistics survey data to build a regression tree. The tree models an establishmentÃ¢â‚¬â„¢s propensity to respond to the survey given certain establishment characteristics. It provides mutually exclusive cells based on the characteristics with homogeneous response propensities. This makes it easy to identify interpretable associations between the characteristic variables and an establishmentÃ¢â‚¬â„¢s propensity to respond, something not easily done using a logistic regression propensity model. This representation is then used along with frame-level administrative wage data linked to sample data to investigate the possibility of nonresponse bias. We show that without proper adjustments the nonresponse does pose a risk of bias and is possibly nonignorable.
U.S. Bureau of Labor Statistics;Analysis of nonresponse to the Longitudinal Occupational Employment Statistics (OES) Survey67;Nonresponse propensity modeling;;Research;Regression Trees with Linear Models;R (rpms package);"This article introduces and discusses a method for conducting an analysis of nonresponse for a longitudinal establishment survey using regression trees. The methodology consists of three parts: analysis during the frame refinement and enrollment phases, common in longitudinal surveys; analysis of the effect of time on response rates during data collection; and analysis of the potential for nonresponse bias. For all three analyses, regression tree models are used to identify establishment characteristics and subgroups of establishments that represent vulnerabilities during the data collection process. This information could be used to direct additional resources to collecting data from identified establishments in order to improve the response rate."
Federal Statistical Office of Germany;Outlier Identification: Isolation Forest;Outlier detection;;Test;Isolation Forest;"R / Package: isofor;    Python / Package: Scikit- learn";"Within the project ""Implementation of the EU definition of the enterprise in business structure statistics"", a donor-based imputation procedure is used for data collection. In order to remove insufficiently plausibilised or ""extreme"" data points from the donor pool, parametric outlier identification methods as well as an ML- based method were tested. Isolation Forest offers low effort in implementation and high efficiency in computing power even when dealing with large (structured) data sets."
Statistics Canada;International Trade data Outliers Detection;Outlier detection;;The outlier detection experiment is completed. The imputation work is in progress.;XGBoost Tree Model;R;"Outliers are a major problem in the international trade data, in particular for the quantity variable. Errors include unit errors, 0 or 1 entered instead of a proper quantity,etc. Current system is based on unit value (UV) clipping, manual checking (including ""unclippingÃ¢â‚¬Â), and an approval process. Machine learning (ML) is used to automate this process. ML is also used to reconstruct/ impute the original value of the flagged points."
U.S. Bureau of Labor Statistics;Outlier Detection Using Unsupervised Learning Under Informative Sampling;Outlier Detection;;Research;k-Means;R;A Bayesian hierarchical modeling approach was developed and applied to Current Employment Statistics survey. This approach is an enhanced k-means method, and it was used to find potential outliers.
Centre for European Economic Research (ZEW);Science4KMU 18;Probabilistic scoring model; Binary classification       ;Prototype;Neural Network;Stata;Assessment of the willingness of companies to cooperate using a neural network based on survey data from the Community Innovation Survey (CIS). The model is designed to make the contact between Technology Transfer Offices (TTO) and companies more efficient.
U.S. Department of Agriculture NASS;Questionnaire consolidation 69;Questionnaire consolidation;;Experiment;Hierarchical Clustering;(SAS);Each state had its own questionnaire version (different states were surveyed on different items at different frequencies), as it was believed that this approach reduced respondent burden.
U.S. Bureau of Labor Statistics;Automatic linkage of fatal injury case information to OSHA records;Record linkage;;Research;Random Forest;Python, Scikit- learn;To produce statistics about fatal occupational injuries in the U.S., the Census of Fatal Occupational Injuries collects and combines information from a wide variety of sources including local, state, and federal government agencies and U.S. media. One of the biggest sources of official information is data from the Occupational Safety and Health Administration, which often investigates fatal work related injuries. One of the key challenges in incorporating this information is figuring out whether an OSHA record corresponds to a record already in the master file, and if so, which one. Often, this must be accomplished even without imperfect identifiers like decedent and establishment name. To address this issue this project uses machine learning, trained on previously linked documents, to automatically determine whether an OSHA investigation document should be linked to an already partially collected case, or represents a new case that should be added to the master file. By combining a variety of noisy and sometimes missing signals including information about the age of the decedent, the date of injury, the location of the incident, and the description of the incident, we can successfully automatically link OSHA records to the master file even without typical identifiers like decedent and establishment name. When this information is available however, our model can link these documents even more effectively. The system is likely to get production use later this summer.
U.S. Bureau of Labor Statistics;Automatic linkage of fatal injury case information to webpage articles.;Record linkage;;Research;Random Forest;Python, Scikit- learn, Spacy, Apache Tika;To produce statistics about fatal occupational injuries in the U.S., the Census of Fatal Occupational Injuries collects and combines information from a wide variety of sources including online media such as news articles. One of the key challenges in incorporating this information is simply finding and matching it to existing case information, often in the absence of even flawed identifiers like decedent name. To address this issue this project uses machine learning, trained on previously linked documents, to automatically determine whether an automatically collected webpage article should be linked to a case already in the master file, or represents a new case that should be added. By combining a variety of noisy signals and by automatically extracting name, date, and establishment information from the article, we hope to be able to conduct this linkage automatically. Systems have already been built to automatically collect these webpages, separate the article text from the rest of the webpage, and automatically extract information like the names of people and companies mentioned in the articles, but more work remains to be done to automatically separate relevant and irrelevant articles.
RKI / FG-31;Automatic outbreak detection for infectious diseases15;Regression;"Regression, classification and information retrieval, anomalies detection
";Research projects and productive operation;HMM, GLM, NLP, classification algorithms (Logistic Regression, Random Forest, SVM, Neural Networks);R, Python;"We develop and implement methods of machine learning for the prediction of case numbers of infectious diseases and for the detection of anomalies in surveillance data. We also use supervised learning approaches to compare and optimize these algorithms. Within the ""Signals 2.0"" project further application research concerning Natural Language Processing for the processing of unstructured data (e.g. protocols, publications) is planned, the extracted information should be made available and also included in the outbreak detection."
IAB;Prediction of duration in unemploy- ment;Regression;;Idea / Feasibility study;Decision Trees, Random Forest, SVM, Neural Networks, Boosting, Ensembles, Stacking;R;In the course of the project, the duration of unemployment is to be predicted by customers of the Federal Employment Agency. The project is explorative. The preliminary goal is therefore to evaluate the potential of machine learning in this context.
GESIS - Leibniz Institute for the Social Sciences;Predicting Genre Preferences from Cultural and Socio- economic Factors for Music Retrieval39;Regression;;Research publication;Gradient Boosting, Random Forest;Python;"Abstract: ""In absence of individual user information, knowledge aboutlarger user groups (e.g., country characteristics) can be exploited forderiving user preferences in order to provide recommendations to users.In this short paper, we study how to mitigate the cold-start problem on acountry level for music retrieval. Specifically, we investigate a large-scaledataset on user listening behavior and show that we can reduce the errorfor predicting the popularity of genres in a country by about 16.4% overa baseline model using cultural and socio-economics indicators."""
 Statistics Austria     ; Estimating a SILC-like income based on adminstrative data;Regression; Estimation/Regressi on    ; Productive     ; Random Forest     ; R     ; For a couple of years now, the household income in the ICT survey is not asked for bute estimated based on adminstrative data and the SILC data.   
Statistics Netherlands;Inference from non- probability samples;Regression;;Experiment;Nearest Neighbor, Neural Network, Regression Tree, Support Vector Machine;R;Different methods are compared to make inference from simulated samples generated through mechanisms other than random sampling to correct for selection bias. Applied to data on annual mileages of vehicles from the Dutch Online Kilometer Registration.
U.S. Bureau of Economic Analysis;Nowcasting of Source Data for Advance GDP Estimates;Regression;;Pilot;Ensemble Methods;R;This pilot effort aims to reduce revisions in key GDP components by improving trending methods. By training an ensemble of ML models (e.g. LASSO, Ridge, Random Forest, etc) using a variety of alternative data, nowcasted predictions are produced for certain source data series in time for the advance estimate of national GDP. Note that this project is currently being evaluated in parallel with the current estimate process.
 Eurostat      ; Euro Area GDP Forecast Using Large Survey Dataset - A Random Forest Approach;Regression      ;; Experiment      ; Random Forest      ; R      ; This paper presents a new statistical approach to forecasting macro- economic aggregates, based on the Random Forests technique, originally developed as a learning classification tool (Breiman, 2001). This technique can handle a very large number of input variables without overfitting and is known to enjoy good prediction properties and to be robust to noise. 
GESIS - Leibniz Institute for the Social Sciences;Measuring Motivations ofCrowd- workers: The Multidimensio nal Crowd- worker Motivation Scale36;Scale development;;Research;Structural Equation Models;R, MPlus, Python, CML;Presents the Multidimensional Crowdworker Motivation Scale (MCMS), a scale for measuring the motivation of crowdworkers on micro-task platforms.
GESIS - Leibniz Institute for the Social Sciences;Extracting Semantics from Random Walks on Wikipedia: Comparing Learning and Counting Methods.41;Text mining;Using DeepWalk (random paths in the network)/ representation learning to extract semantic relatedness and generate paths from the Wikipedia link structure;Research publication;Deep Learning;Python;"Abstract: ""Semantic relatedness between words has been extracted from a variety of sources. In this ongoing work, we explore and compare several options for determining if semantic relatedness can be extracted from navigation structures in Wikipedia. In that direction, we first investigate the potential of representation learning techniques such as DeepWalk in comparison to previously applied methods based on counting co-occurrences. Since both methods are based on (random) paths in the network, we also study different approaches to generate paths from Wikipedia link structure. For this task, we do not only consider the link structure of Wikipedia, but also actual navigation behavior of users. Finally, we analyze if semantics can also be extracted from smaller subsets of the Wikipedia link network. As a result we find that representation learning techniques mostly outperform the investigated co- occurrence counting methods on the Wikipedia network. However, we find that this is not the case for paths sampled from human navigation behavior."""
National Institute of Statistics Romania;Price index estimation using web scraped data;String matching;;Experimental;Levenshtein distance;R;Levenshtein distance between two strings is the number of deletions, insertions or substitutions required to transform source string into target string. This string matching technique is necessary for automatic classification of products names into categories and across periods.
Institut national de la statistique et des ÃƒÂ©tudes ÃƒÂ©conomiques (INSEE);Use of machine learning algorithms for nonresponse issues through reweighting;Supervised algorithms;;Ongoing study;Random Forest, Bagging, Boosting, CART, Gradient Boosting Tree, Group Lasso.;R;The objective of this study is to improve the quality of nonresponse treatments in a general context of increasing nonresponse rates in both firm and household surveys. We want to explore the ability of machine learning algorithms to take the full advantage of the huge amount of auxiliary information coming from different horizons such as, paradata, administrative data, location information, etc, in a very flexible way. Exporatory works are run on the Adult education survey and the Structural Business Statistics Survey.
 Institut national de la statistique et des ÃƒÂ©tudes ÃƒÂ©conomiques (INSEE)  ; Nowcasting short-term business indicators with media information ;Text mining, machine learning, semantical analysis    ;; Studies      ; Dictionary-based approaches, Deep Learning (Word2vec), Penalized Regression (elasticnet);       ; Several experiments aimed to assess the performance of nowcasting different business indicators (e.g. GDP, payroll employment) with google trends, and traditional media information.    
GESIS - Leibniz Institute for the Social Sciences;Polylingual Labeled Topic Model33;Topic Model;;Research publication;PLL-TM;Julia, CML;Development and evaluation of the Polylingual Labeled Topic Model
GESIS - Leibniz Institute for the Social Sciences;Election Campaigning on Social Media: Politicians, Audiences and the Mediation of Political Communi- cation on Facebook and Twitter28;Topic Modelling;;Research publication;Semi-supervised classification;Juliet;"Abstract: ""Although considerable research has concentrated on online campaigning, it is still unclear how politicians use different social media platforms in political communication. Focusing on the German federal election campaign 2013, this article investigates whether election candidates address the topics most important to the mass audience and to which extent their communication is shaped by the characteristics of Facebook and Twitter. Based on open-ended responses from a representative survey conducted during the election campaign, we train a human-interpretable Bayesian language model to identify political topics. Applying the model to social media messages of candidates and their direct audiences, we find that both prioritize different topics than the mass audience. The analysis also shows that politicians use Facebook and Twitter for different purposes. We relate the various findings to the mediation of political communication on social media induced by the particular characteristics of audiences and sociotechnical environments."""
GESIS - Leibniz Institute for the Social Sciences;When populists become popular: comparing Facebook use by the right- wing movement Pegida and German political parties29;Topic Modelling;;Research publication;LDA;Python;"Abstract: ""Previous research has acknowledged the use of social media in political communication by right-wing populist parties and politicians. Less is known, however, about its pivotal role for right- wing social movements which rely on personalized messages to mobilize supporters and challenge the mainstream party system. This paper analyses online political communication by the right-wing populist movement Pegida and German political parties. We investigate to which extent parties attract supporters of Pegida, to which extent they address topics similar to Pegida and whether their topic use has become more similar over a period of almost two years. The empirical analysis is based on Facebook posts by main accounts and individual representatives of these political groups. We first show that there are considerable overlaps in the audiences of Pegida and the new challenger in the party system, AfD. Then we use topic models to characterize topic use by party and surveyed crowd workers to which extent they perceive the identified topics as populist communication. The results show that while Pegida and AfD talk about rather unique topics and smaller parties engage to varying degrees with the topics populists emphasize, the two governing parties CDU and SPD clearly deemphasize those. Overall, the findings indicate that the considerable attention devoted to populist actors and shifts in public opinion due to the refugee crisis have left only moderate marks in political communication within the mainstream party system."""
Federal Statistical Office of Germany;Machine Learning Methodology 13;Various;Evaluation of ML  as a possibility for implementing automated data preparation and data analysis.;Tests;kNN, Naive Bayes, Random Forest, SVM, ANN, ...;R, Python, HoloClean;Evaluation of machine learning processes as a possibility for implementing automated data preparation and data analysis
Italian National Institute of Statistics;Substitutes for surveys via internet scraping47;;;Experiment;Naive Bayes and others;R;Research regarding the possibility of substituting (fully or partially) surveys by collecting data via internet scraping and extracting information therein using machine learning methods.
Statistics Canada;Manufacturing industries and producer prices commodities;;Data extraction, Classification to NAPCS;At test stage, experimentation to start in May'18;TBD;R, Python;Web scraping to obtain the list of commodities being produced by manufacturing companies from catalogues on their Web sites or other existing on-line data bases. Code the products to the NAPCS classification using ML.
Statistics Canada;Agriculture crop yield estimates54;;Predictive modelling;Phase 1 in production since 2015 Phase 2 (November crop yield and area) at Idea stage, to start in May'18;Phase 1 : LASSO and others Phase 2 : TBD;"mostly SAS for phase 1; TBD for phase 2";Phase 1 : The model-based crop estimates provide provincial and national yield and production estimates for principal field crops in Canada. The model utilizes data from low resolution satellite imagery, historical field crop survey estimates, and agroclimatic information. Phase 2: Develop in season crop area and yield estimates, combining crop insurance, remote sensing and other business intelligence including supply and disposition data and historical patterns to identify likely crop cover at the field level and then employing historical data, trends and weather data to produce yield estimates.
Statistics Canada;Canadian Housing Statistics Program, project on citizenship and country of birth;;Classification;Idea, to start in May'18;TBD;TBD;Partial information about citizenship and country of birth can be found in different databases such as the Census of Population, the Social Insurance Number Registry, immigration data, tax data, and so on. Standardize and integrate the existing information, use ML to impute missing information.
Statistics Canada;Exploration of machine learning to create indicators on tourism spending;;Regression;Idea;TBD;TBD;Model a set of early indicators on international tourism spending in Canada based on survey data and payment processor data from debit and credit cards.
Statistics Canada;Economic Analysis: Identifying high growth firms and firm failures;;Classification;Idea, to start in May 2018;Random Forest;R;Administrative data over a three-year time span is commonly used to identify high growth firms. This project uses ML techniques to develop more timely estimates of high growth firms. Similarly, firm peformance is hypothesized to deteriorate years before exit (shadow of death effect).    ML techniques are also applied to develop more timely estimates of firm exits.
 Statistics Canada     ; Economic Analysis: Identifying firm networks  ;;Classification; Initial assessment completed. Additional data needed to improve algorithm.; TBD     ; TBD     ; Using ML to identify firm networks from Business Register and origin and destination of shipments data so that supply chains and intra- and intra-firm trade can be analysed   
 Statistics Canada       ; Communicatio ns and Dissemi- nation: improving user experience on the web;; Chatbots       ; Idea       ; TBD       ; TBD       ; Live chat featured for visitors based on their navigation patterns       
 Statistics Canada       ; Communi- cations and Dissemi- nation: improving user experience on the web;; TBD       ; Idea, to start in April 2018      ; TBD       ; TBD       ; Use AI to analyze content web site visitors based on their past content consumption / navigation, or to offer live chat.      
 Statistics Canada               ; Predicting Mortality Rates             ;; Predictive modelling               ; Idea to start in FY 2018              ; TBD               ; TBD               ; Investigate how sociodemographic and health-related factors contribute to life expectancy. Constructing well-specified predictive models can be extremely time consuming and labor intensive. Data driven approaches, like machine learning techniques, are gaining popularity. These algorithms may be able to gain insightful information about what predicts an outcome by iteratively learning from data, instead of being explicitly directed by theory ML solution: Trial various AI/machine learning techniques, including support vector machines and neural networks, to predict mortality in the Census linked CANCHEC cohorts. These are large cohorts that contain health outcomes, but not necessarily health exposure data. As Statistics Canadas holdings of such data increase we need to explore alternative methods to construct robust predictive models/analytic tools, when we are lacking key health exposure variables.
Statistics Canada;Victimisation studies (Harvesting key data from narrative descriptions);;Classification;Idea, to start in Spring/Summer 2018 (data dependent);Text recognition (possibly), Natural language processing, TBD;TBD;Exploring narrative descriptions to harvest statistical information (abuse case in social workersÃ¢â‚¬â„¢ narrative description)
Statistics Canada;R&D for generalised systems55;;Sample allocation/selection;Proof of concept completed;Genetic Algorithm;R;Use of genetic algorithm (AI based on natural selection) for sample allocation
Statistics Canada;Census;;Imputation;Completed and used for Census 2016 production;ReliefF algorithm for feature selection and weigthing for neirest neighbor imputation;"R for feature selection and weigthing; model used in ""regular"" production system ( CANCEIS)";Immigration admission category variables were added to the 2016 Census through record linkage rather than collecting them from respondents. Data were not available for some individuals and had to be inferred from other characteristics provided by them. Machine Learning was used to identify the best combination of characteristics to make these inferences.
 Statistics Canada       ; Exploration of machine learning for coding of industry and occupation text descriptions;; Statistical coding       ; Exploratory / idea generation      ; Various       ; Various       ; Opportunities to use Machine Learning and Artifical Intelligence to improve the effectiveness of automated coding of survey responses is being investigated. This would have a number of applications in survey and administrative data programs, including the Labour Force Survey. For example, new methods could permit the collection of additional open-ended information related to task descriptions of jobs and skills profiles of individuals. 
 Statistics Canada   ; Census Program Transfor- mation Project;; To be defined   ; Idea   ; TBD   ; TBD   ; Exploring how AI could be applied in data linkage processes in the building of statistical registers.  
 Statistics Canada ; Synthetic Data File;; Synthetic data (disclosure control); Exploration ; CART models and Random Forest; R ; Examination of machine learning algorithms for creation of synthetic data for disclosure control
 Statistics Canada  ; Priorisation score for collection;;   ; Exploration / proof of concept in progress; Bayesian Hierarchical ; SAS  ; Creating a Priorization Score in CATI Surveys: Analysis of the Bayesian Hierarchical Rule Modeling 
 Statistics Canada         ; Simulation of administrative data       ;; Modelling         ; Idea         ; TBD         ; TBD         ; Modeling of administrative data which can incorporate both the relationships between variables (correlations) and the longitudinal dependences are requirements to provide realistic simulated data for statistical purposes. Current methodology and available tools apply Gibbs Sampling or Bayesian networks to model all the conditional distributions. Machine learning algorithms may also provide a solution. For example, neural networks are capable of modeling complex correlations amongst variables. Such networks could be extended to deep networks in the case of large, complicated data sets.
 Statistics Canada      ; Development of the record linkage software G- Link  ;; Probabilistic record linkage with Fellegi- Sunter methodology    ; Development      ; Unsupervised: K- Means Supervised: two- step method K- means + Probit  ; G-Link (coded in SAS)     ; Supervised and Semi-supervised Machine Learning methods are used for the development of automatic thresholds in the Felleigi- Sunter methodology. The k-means method and the two-step method (k-means and probit) will be implemented in the version 3.4 of G- Link. In this way, Statistics Canada is creating an opportunity to replace costly searches carried out by humans through manual review by machine learning techniques.
Statistics Iceland;Increased automation in data processing;;Varied;Planning;;;
 Statistics Netherlands   ; Domain names ICT companies  ;;     ; Experiment    ;     ; Python    ; A nation wide URL domain name data base (the .nl domain) is connected to the outcome of the Dutch ICT-company survey in order to create a ML-trainingset based on the web-scraped contents of the company's URL. In this way, ICT-company classification can be automated and the ICT-company statistics can be improved
 Statistics Netherlands   ; Prediction of economic activity from website texts60;; Multiple cases    ; Test    ; Various ML techniques like SVM and Random Forest  ; R and Python    ; Economic activity is an important characteristic of enterprises. This characteristic is stored in a General Business Register at CBS, but it tends to be outdated. We aim to use machine learning techniques to predict the economic activity from website texts 
 Statistics Netherlands  ; Deep learning - Estimating missing values;Imputation;Estimate missing turnover data of companies by DNN; Experiment   ; Deep Learning; Python   ; Turnover data of companies contain a lot of missing values. Imputation techniques may be improved by using machine learning techniques. The aim of this study is to estimate missing values by using deep learning.
 Statistics Poland        ; Detection of agricultural crops62      ;; Segmentation        ; Pilot        ; KNN, SVM        ; MTSar, ArcGIS        ; The goal is to identify crop types based on Sentinel-1 and Sentinel-2 satellite images. Different algorithms have been tested for the detection of crop types, including Support Vector Machine (SVM), Decision Trees (DT), K-Nearest Neighbours (KNN) with the following classification parameters: Sigma, Entropy, Alfa, multi-temporal indicators, Wishard distribution but the highest accuraccy is based on KNN with wishard distribution.
 Statistics Poland      ; Life satisfaction     ;;Classification; Pilot      ; NL      ; Python, MongoDB, Apache Spark     ; The goal of the use case is to deliver data on life satisfaction - 1.happy, 2.neutral, 3.calm, 4.upset, 5.depressed and 6.discouraged. The goal is to support the data from EU-SILC survey with more recent data. The major drawback from this case study is that the dataset may not be representative. The methodology includes Machine learning Ã¢â‚¬â€œ supervised learning and Web scraping Ã¢â‚¬â€œ we use Twitter API to gather and process the data.
 Statistics Portugal     ; Identification of error- containing records via classification trees63;; Error detection     ; Experiment     ; Decision Tree     ;      ; A method based on classification trees for error detection in foreign trade transaction data collected by the Portuguese Institute of Statistics.   
 Statistics Spain (INE) ; UFAES (new methodology) ;; Algorithm-assisted survey sampling ; Research with real data ; Random Forest  ; R  ; Random forests are used to model questionnary data from admin data. This model assists the design-based estimator in a probability sampling survey in order to reduce the sample size.
 Statistics Spain (INE)  ; Selective Editing of Quantitative Variables;; Prediction   ; Planning stage   ; Random Forest, SVMs, Spline Regression, kNN Regression; R   ; Different predictive techniques are to be explored to predict anticipated values in the optimization approach to selective editing of quantitative variables developed at Statistics Spain (INE) 
 U.S. Department of Agriculture NASS     ; Crop Prediction Based on the Cropland Data Layer, Administrative Data, and Survey Data;;Matching; Foundational work is being undertaken     ; TBD, probably Bayesian      ; TBD, likely R or SAS with others Source (link)     ; An effort to bring all available data together to enhance crop forecasts of crop yield      
